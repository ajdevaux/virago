#! /usr/bin/env python
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pandas as pd
import numpy as np
from scipy import stats
import glob, os

pd.set_option('display.width', 1000)
os.chdir('/Users/dejavuax/ResilioSync/NEIDL/DATA/IRIS/pCHIP_results/pCHIP001data')
if not os.path.exists('virago_output'):
    os.makedirs('virago_output')
full_times = pd.DataFrame([])
spot_data = pd.DataFrame([])
filtered_counts, filtered_density2 = ([]) , ([])
spot_labels = []

for file in glob.glob('*.txt'): ##Text file parser
    txtfile = file
    print('File scanned:  '+ txtfile)
    data = pd.read_table(txtfile, sep = ':', error_bad_lines = False, names = ("Parameter", "Value"), index_col = 0)
    #print(data)
    if 'chip_name' in data.index: ##This parses text in text files generated by IRIS instrument
        real_times, pass_labels = [], []
        i = 1
        spot_type = pd.Series(data.loc['spot_type'])
        spot_type = str(spot_type.values)
        spot_type = spot_type[2:-2]
        spot_labels.append(spot_type)
        for row in data.iterrows():
            if i < 10:
                pass_time = 'pass_time00' + str(i)
                if pass_time not in data.index:
                    break
                else:
                    time_sec = data.loc[pass_time]
                    time_min = round(float(time_sec) / 60, 2)
                    real_times.append(time_min)
                    pass_labels.append(pass_time)
                    i += 1
            elif 10 <= i < 100:
                pass_time = 'pass_time0' + str(i)
                if pass_time not in data.index:
                    break
                else:
                    time_sec = data.loc[pass_time]
                    time_min = round(float(time_sec) / 60, 2)
                    real_times.append(time_min)
                    pass_labels.append(pass_time)
                    i += 1
    elif 'data_file' in data.index: ##This parses text files generated by nanoViewer software
        data_file = str(data.loc['data_file'].values)
        scan_number = int(data_file[15:-2])
        spot_number = int(data_file[11:-6])
        count = int(data.loc['count'])
        area = float(data.loc['area'])
        density = round(count / area, 2)
        solo_spot_data = pd.DataFrame([spot_number, scan_number, count, area, density]).T
        spot_data = pd.concat([spot_data, solo_spot_data], axis = 0, ignore_index = True)
        continue
    else:
        continue
    real_times2 = pd.Series(real_times)
    #print(real_times2)
    full_times = pd.concat([full_times,real_times2], axis = 1, ignore_index = True)
#print(spot_labels)
full_times.columns = [np.asarray(spot_labels)]
full_times.index = [pass_labels]

chip_name = data.loc['chip_name']
chip_name = str(chip_name.values)
chip_name = chip_name[2:-2]

#print(full_times)
#print(spot_data)

hist_dict = {}
for file in glob.glob('*.csv'): ##This pulls particle data from the CSVs generated by nanoViewer
    csvfile = file
    data2 = pd.read_table(csvfile, sep = ',', error_bad_lines = False, names = ("Contrast", "Correlation", "X-coord", "Y-coord", "Slice No."), index_col = 0)
    #print(data2)
    k, particles_65, particles_75, particles_85 = 1,0,0,0
    corr65_75, corr75_85, corr85 = pd.DataFrame([]), pd.DataFrame([]), pd.DataFrame([])
    for row in data2.iterrows():
        contrast = data2.get_value(k, 'Contrast')
        contrast = (contrast - 1) * 100
        corr = data2.get_value(k, 'Correlation')
        if 0 < contrast <= 10 and 0.65 <= corr < 0.75:
            filter65_75 = pd.DataFrame([contrast, corr]).T
            corr65_75 = pd.concat([corr65_75, filter65_75], ignore_index = True)
            k += 1
            particles_65 += 1
            continue
        elif 0 < contrast <= 10 and 0.75 <= corr < 0.85:
            filter75_85 = pd.DataFrame([contrast, corr]).T
            corr75_85 = pd.concat([corr75_85, filter75_85], ignore_index = True)
            k += 1
            particles_65 += 1
            particles_75 += 1
            continue
        elif 0 < contrast <= 10 and corr >= 0.85:
            filter85 = pd.DataFrame([contrast, corr]).T
            corr85 = pd.concat([corr85, filter85], ignore_index = True)
            k += 1
            particles_65 += 1
            particles_75 += 1
            particles_85 += 1
            continue
        else:
            k += 1
            continue

    csv_id = csvfile[9:-4]
    hist_dict[csv_id + '-corr65_75'] = np.asarray(corr65_75.iloc[:,0])
    hist_dict[csv_id + '-corr75_85'] = np.asarray(corr75_85.iloc[:,0])
    hist_dict[csv_id + '-corr85'] = np.asarray(corr85.iloc[:,0])
    filtered_counts.append(particles_75)
    spot_id = int(csvfile[9:-8])
    pass_id = int(csvfile[13:-4])
    print('File scanned:  '+ csvfile)
    #print('Scanning: spot '+ str(spot_id) + ' pass '+ str(pass_id) + '...')
    ##Histogram generator for each CSV dataset

spots_to_hist = input("Which spots would you like to generate histograms for?\t")
print(spots_to_hist)
for key in sorted(hist_dict.keys()):
    pass_count = 1
    if spots_to_hist == int(key[:3]) and pass_count == int(key[4:7]):
        print(key)
        plt.hist([hist_dict[key[:3] + '.00' + str(pass_count) + '-corr65_75'], hist_dict[key[:3] + '.00' + str(pass_count) + '-corr75_85'], hist_dict[key[:3] + '.00' + str(pass_count) + '-corr85']], 100, range = [0,10], color = ['#0000FF', '#0088FF', '#003366'], stacked = True, rwidth = 0.75, alpha = 0.75)
        plt.xlabel("Percent Contrast")
        plt.grid(True)
        plt.ylabel("Particle Count")
        plot_title = str("Particle Contrast Distribution of " + chip_name + '_' + key[:7])
        plt.title(plot_title)
        plt.savefig('virago_output/' +  chip_name + '_' + key[:7] + '-histo.svg', bbox_inches = 'tight', pad_inches = 0.1)
        print('File generated: ' +  chip_name + '_' + key[:7] + '-histo.svg')
        plt.clf()
    pass_count += 1
filtered_counts = pd.Series(filtered_counts)
spot_data = pd.concat([spot_data, filtered_counts], axis = 1, ignore_index = True)
for row in spot_data.iterrows():
    filtered_density = (spot_data.iloc[:,5] / spot_data.iloc[:,3])/1000
spot_data = pd.concat([spot_data, filtered_density], axis = 1)
#i = 0
#for row in spot_data.iterrows():
    #l = spot_data.iloc[:,1].values
    #if l.any() == int(1):
    #    filtered_density_adj = 0
    #    print(filtered_density_adj)
    #    i += 1
    #else:
    #    filtered_density_adj = spot_data.iloc[i,6] - spot_data.iloc[0,6]
    #    i += 1
    #    print(filtered_density_adj)
spot_data.columns = ['spot_number', 'pass_number', 'unfiltered_count', 'area', 'unfiltered_density', 'filtered_count', 'filtered_density']

##Time data plot
n = 0
for column in full_times:
    time_x = np.asarray(full_times.iloc[:,n])
    density_y = np.asarray(spot_data.loc[n*(i-1):(n*(i-1))+(i-2),'filtered_density'])
    plt.plot(time_x, density_y, '-o', label = full_times.columns[n])
    plt.xlabel("Time (min)")
    plt.ylabel("Particle Density (kparticles/sq. mm)")
    plt.title(chip_name)
    plt.legend()
    n += 1
plt.show()
plt.clf()

full_times.to_csv('virago_output/timestamps_' + chip_name + '.csv', sep = ',')
spot_data.to_csv('virago_output/spot_data_' + chip_name + '.csv', sep = ',')
